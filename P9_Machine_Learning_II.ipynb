{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "P9 - Machine Learning II.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "PUxdctIdxU6B"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 2",
      "language": "python",
      "name": "python2"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.13"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mindab/Model-Prediction-Using-Machine-Learning-/blob/main/P9_Machine_Learning_II.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PUxdctIdxU6B"
      },
      "source": [
        "---\n",
        "---\n",
        "\n",
        "Applied Data Science in Python for Social Scientists\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "---\n",
        "#Start Here\n",
        "## Learning Goals\n",
        "### General Goals\n",
        "- Learn the fundamental concepts of applied machine learning\n",
        "- Learn the fundamental concepts of supervised learning\n",
        "\n",
        "### Specific Goals\n",
        "- Learn the basics of regression\n",
        "- Learn to apply different models of regression:\n",
        "    - linear regression\n",
        "    - polynomial regression\n",
        "    - kNN regression\n",
        "- Understand bias-variance tradeoff\n",
        "- Learn to apply cross validation\n",
        "- Learn to apply regularization (L1 vs. L2)\n",
        "- Learn to evaluate and compare the performance of your regression models\n",
        "- Learn to apply feature scaling\n",
        "- Feature engineering\n",
        "- Understand transfer learning\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3SWf22cCjQNY"
      },
      "source": [
        "# Part I: Predicting the Prevalence of the CCD Disease (80 points)\n",
        "\n",
        "For a long time now, humans of the **United States of America (USA)** have been suffering from a communicable disease called the CCD, short for the **Climate Change Denialism**, a serious disease that is making humans incapable to reason. True story! <sup>1</sup>\n",
        "\n",
        "The Center of Logical Reasoning has been collecting the data related to the disease since 2010, and has reached out to NYU for help in creating a model for the prediction of the prevalance of **Climate Change Denialism** in different states using a set of features. The dataset is **spatio-temporal** as it has prevalance rates of the disease for ~50 states (spatial), across 7 years (temporal).\n",
        "\n",
        "------------------\n",
        "<sup>1. This is a work of fiction. The story, names, writing, data depicted in this problem set are mostly ficticious. Any similarity to actual persons, living or dead, or to actual papers, is not purely coincidental but definitely inspirational. The \"Climate Change Denialism\" is a fictitious disease that may have been inspired by a same name disorder found amongst certain individuals in the world.</sup>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wfGNVsfFlYHV"
      },
      "source": [
        "## A. Training for the US (45 points)\n",
        "\n",
        "Using the dataset `us_train.csv`, train a machine learning based regression model that predicts the prevalence of **Climate Change Denialism** disease for a particular state in the USA. The features are in the columns labeled as `A`, `B`, ..., `AC`. The outcome variable (i.e. the prevalence of CCD disease) is present in the column `outcome`. \n",
        "\n",
        "You may try different models (linear, polynomial, kNN) to see which one performs the best for estimation of the prevalence of the disease. You have data for the years 2010 to 2015 for 50 states in the U.S. Your data will be tested on data from 2016. The features for 2016 are provided in the file `us_test_x.csv`. The outcome/labels for 2016 are not provided.\n",
        "\n",
        "For this part, you are required to train and evaluate your regression models very similar to what we did in the recitation.\n",
        "\n",
        "As a submission for this part, you will fill the `us_predictions.csv` file and submit that along with this Notebook to NYU Classes. You will also submit `us_predictions.csv` file to Kaggle (see Part B)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0DHhFABDkXB6"
      },
      "source": [
        "# Importing libraries you \"may\" need\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.metrics import mean_absolute_error, r2_score\n",
        "from scipy import stats\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.model_selection import GridSearchCV"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5lHr1i-Eq2ID",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7878f09b-0ade-4f0b-f718-1f77e2800d75"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6w8e8nPCHCE6"
      },
      "source": [
        "us_train = pd.read_csv(\"/content/drive/My Drive/Data_Science/Assignment/hw9_handout/us_train.csv\")\n",
        "us_test = pd.read_csv(\"/content/drive/My Drive/Data_Science/Assignment/hw9_handout/us_test_x.csv\")\n",
        "\n",
        "us_train = us_train[us_train.year != 2010]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XgHWu2DyHPBy"
      },
      "source": [
        "#getting dummies and scaling train and test features\n",
        "scaler = MinMaxScaler()\n",
        "x_train = us_train.drop(['Id', 'year', 'outcome'], axis=1)\n",
        "x_train = pd.get_dummies(x_train, columns=['states'], prefix=\"\", prefix_sep=\"\")\n",
        "x_train.iloc[:,0:29] = scaler.fit_transform(x_train.iloc[:,0:29])\n",
        "y_train = us_train['outcome']\n",
        "\n",
        "x_test = us_test.drop(['Id', 'year'], axis=1)\n",
        "x_test = pd.get_dummies(x_test, columns=['states'], prefix=\"\", prefix_sep=\"\")\n",
        "x_test.iloc[:,0:29] = scaler.transform(x_test.iloc[:,0:29])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fb0KVTLyHTLP",
        "outputId": "869eec9d-13e1-456f-fa36-1d21ebc1ffd6"
      },
      "source": [
        "Defining a range of alpha values for Lasso\n",
        "alphas = np.linspace(0.01,1,100)\n",
        "#alphas = np.linspace(0.0001,1,100)\n",
        "\n",
        "# Initializing the instance of lasso\n",
        "lasso = Lasso()\n",
        "\n",
        "# Setting parameter grid for grid search\n",
        "param_grid = {'alpha': alphas}\n",
        "\n",
        "# defining grid search with 5-fold cross validation\n",
        "grid_search = GridSearchCV(lasso, param_grid, scoring='r2', cv = 5)\n",
        "\n",
        "# fitting the train\n",
        "grid_search.fit(x_train, y_train)\n",
        "\n",
        "# Printing the best set of parameters\n",
        "print('Best parameters{}'.format(grid_search.best_params_))\n",
        "\n",
        "# Printing the best score (here score is R squared score)\n",
        "print('Best score {}'.format(grid_search.best_score_))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best parameters{'alpha': 0.0001}\n",
            "Best score 0.761925971322\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7yiXWfJzHXy5",
        "outputId": "1c2226e7-eaf7-4ae7-ab2b-84b620a1c948"
      },
      "source": [
        "linear_lasso_optimal = Lasso(alpha=grid_search.best_params_['alpha'])\n",
        "linear_lasso_optimal.fit(x_train, y_train)\n",
        "\n",
        "def evaluate(x,y, model):\n",
        "        print (\"Train mean_absolute_error (MSE)\", \n",
        "               mean_absolute_error(y, model.predict(x)))\n",
        "        print (\"Train R-squared Score (R2)\", \n",
        "               r2_score(y, model.predict(x)))\n",
        "\n",
        "evaluate(x_train, y_train, linear_lasso_optimal)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('Train mean_absolute_error (MSE)', 0.3325357408961107)\n",
            "('Train R-squared Score (R2)', 0.9327949017139796)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qtkgeMQJJgdh",
        "outputId": "9c6776d7-16e7-4348-e6b4-ca4ade220a3c"
      },
      "source": [
        "linear_lasso_optimal.predict(x_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([12.95006068,  7.24689784, 10.47157262, 12.34292907, 10.1660963 ,\n",
              "        7.25417224,  9.48093502, 11.1867625 ,  8.66226608, 11.11000771,\n",
              "       11.51239037,  8.75550547, 10.33973038, 11.6178218 ,  9.46105172,\n",
              "        9.59259171, 12.11156369, 12.43212198, 10.14244893, 10.16737968,\n",
              "        9.30661649, 10.98165648,  8.10875611, 14.23688732, 11.76190856,\n",
              "        8.45777062,  8.80864424, 10.17639623,  8.87686547,  9.8443763 ,\n",
              "       11.29214099, 10.56621889, 11.43967284,  8.48577688, 11.51658872,\n",
              "       12.25187071,  9.62781068, 10.89096339,  9.38529519, 12.85377601,\n",
              "        8.85920709, 12.63232884, 11.17607157,  7.37922165,  8.19374114,\n",
              "       11.00028022,  9.16724243, 13.80006748,  8.8737233 ,  8.33670379])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 214
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HldCpsjvHwDV"
      },
      "source": [
        " #This model is the best and is my final submission on kaggle\n",
        "us_predictions=pd.DataFrame()\n",
        "us_predictions['Id']=us_test['Id']\n",
        "us_predictions['Predicted'] = pd.DataFrame(linear_lasso_optimal.predict(x_test))\n",
        "output_dir = '/content/drive/My Drive/Data_Science/Assignment/'\n",
        "us_predictions=us_predictions.to_csv(output_dir+'us_predictions.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DpGGhML3K_jp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8c7805d-432d-4dd1-92be-bf510835e2e2"
      },
      "source": [
        "\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "\n",
        "k_range = list(range(1,31))\n",
        "weight_options = [\"uniform\", \"distance\"]\n",
        "\n",
        "param_grid = dict(n_neighbors = k_range, weights = weight_options)\n",
        "knn = KNeighborsRegressor()\n",
        "\n",
        "grid = GridSearchCV(knn, param_grid, cv = 10)\n",
        "grid.fit(x_train,y_train)\n",
        "\n",
        "\n",
        "print (grid.best_score_)\n",
        "print (grid.best_params_)\n",
        "print (grid.best_estimator_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8452447874650099\n",
            "{'n_neighbors': 4, 'weights': 'distance'}\n",
            "KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
            "          metric_params=None, n_jobs=None, n_neighbors=4, p=2,\n",
            "          weights='distance')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nt88bK9ILMwL",
        "outputId": "5f0d1fd6-f2ba-4068-8b14-430c1b6961d9"
      },
      "source": [
        "best_params = grid.best_params_\n",
        "knn = KNeighborsRegressor(n_neighbors=best_params['n_neighbors'], weights=best_params['weights'])\n",
        "knn.fit(x_train,y_train)\n",
        "predicted_value = knn.predict(x_test)\n",
        "predicted_value"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([12.50416177,  7.49634181, 10.31328029, 12.18417014, 10.07277267,\n",
              "        6.92137454,  9.21301559, 10.82459608,  8.30793724, 11.2612335 ,\n",
              "       11.02552475,  8.0942518 ,  9.84831511, 11.09005695,  9.19400134,\n",
              "       10.00226594, 12.49260391, 12.33955318, 10.34863907, 10.03362608,\n",
              "        8.91586911, 10.41203039,  7.61568761, 14.0475303 , 10.96107948,\n",
              "        7.95248145,  8.85979001,  9.48908416,  8.68742422,  9.21762938,\n",
              "       11.08825391,  9.9464195 , 10.80405082,  8.70154992, 11.11409767,\n",
              "       11.20925405,  9.85155634, 10.61883127,  9.27022143, 11.95672555,\n",
              "        8.96331215, 12.54018888, 11.08131223,  7.07402586,  7.84612827,\n",
              "       10.31897743,  8.60707925, 13.6999051 ,  8.4700293 ,  8.56157496])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 200
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4t6LkS8vYO5H"
      },
      "source": [
        "us_predictions=pd.DataFrame()\n",
        "us_predictions['Id']=us_test['Id']\n",
        "us_predictions['Predicted'] = pd.DataFrame(knn.predict(x_test))\n",
        "us_predictions.rename(columns={0: 'Predicted'},inplace=True)\n",
        "output_dir = '/content/drive/My Drive/Data_Science/Assignment/hw9_handout/'\n",
        "us_predictions_knn=us_predictions.to_csv(output_dir+'us_predictions_knn.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OoSZ0d_jaBYH"
      },
      "source": [
        "### Rubric\n",
        "\n",
        "- +25 points for logical and reasonable steps to training and testing the models using the techniques taught in the course\n",
        "- +20 points showing code and evaluation of **at least two regression models** at least one of which makes the same predictions as submitted on Kaggle and in the document `us_predictions.csv`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IQkC-_qeYvnL"
      },
      "source": [
        "## B. Kaggle Submission (35 points)\n",
        "\n",
        "Create an account on Kaggle, and submit your predictions as `us_predictions.csv` with the two columns `Id` and `Predicted` to Kaggle [here](https://www.kaggle.com/t/c621fd11faca492eb4db37ff5b9f78f0). \n",
        "\n",
        "You will be evaluated on the `Mean Absolute Error` as a scoring metric.\n",
        "\n",
        "There are seven benchmarks/baselines that we have provided you on Kaggle. These are as follows: \n",
        "\n",
        "- `Trivial Baseline`\n",
        "- `Baseline A (1 and 2)`\n",
        "- `Baseline B (1 and 2)`\n",
        "- `Baseline C (1 and 2)`\n",
        "\n",
        "To be able to get full points on this task, you would need to pass the `Trivial Baseline`, either of `A1` or `A2`, either of `B1` or `B2`, **and** either of `C1` or `C2` baseline.\n",
        "\n",
        "Note that the score you see on Kaggle Leaderboard for your submission is only based on 50% of the test dataset (i.e. 25 data points) -- we have hidden the other 50% of the dataset, and your score on those will only be revealed once the competition ends. In general, if you pass the baseline on the publicly available data, your model should pass the baselines on the hidden data as well. But we have kept it hidden so that you don't overfit your model on the test set. \n",
        "\n",
        "The Kaggle data points for the test set are from 2016 the features for which are provided in `us_test_x.csv`. \n",
        "\n",
        "You have a maximum for 10 submissions per day on Kaggle. Before submitting the notebook, enter your Kaggle username in the **Kaggle Username** section above."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NH5VV_UXWFZe"
      },
      "source": [
        "### Rubric\n",
        "\n",
        "- +10 points for achieving/crossing Baseline A1 or Baseline A2 across both public (7 points) and hidden data points (3 points).\n",
        "- +5 points for achieving/crossing Trivial Baseline across both public (3 points) and hidden data points (2 points).\n",
        "- +10 points for achieving/crossing Baseline B1 or Baseline B2 across both public (7 points) and hidden data points (3 points).\n",
        "- +10 points for achieving/crossing Baseline C1 or Baseline C2 across both public (7 points) and hidden data points (3 points).\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "goGyqP7dnRhU"
      },
      "source": [
        "## *Concepts required to complete this task*\n",
        "\n",
        "*   Basics of Machine Learning\n",
        "*   Basics of Regression\n",
        "*   Feature Engineering\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IuRYqcxmn4vS"
      },
      "source": [
        "# Part II: Transfer Learning (40 points)\n",
        "\n",
        "Many machine learning methods work well only under a common assumption: the training and test data are drawn from the same feature space and/or the same distribution. When the distribution changes, most statistical models need to be rebuilt from scratch using newly collected training data. In many real world applications, it is expensive or impossible to recollect the needed training data and rebuild the models. It would be nice to reduce the need and effort to recollect the training data. In such cases, **knowledge transfer** or **transfer learning** between task domains would be desirable. \n",
        "\n",
        "**Transfer learning** is a machine learning method where a model developed for a task is reused for a model on a second task. For example, in the paper on *Revealing Inherent Gender Biases in Using Word Embeddings for Sentiment Analysis* in PS7, the (imaginary) authors used word embeddings for sentiment analysis. That was a transfer learning approach where word embeddings were created from a machine learning model that was trained for the purpose of [predicting words](https://machinelearningmastery.com/develop-word-based-neural-language-models-python-keras/#:~:text=Language%20modeling%20involves%20predicting%20the,machine%20translation%20and%20speech%20recognition.), but the model was later **reused** to extract word embeddings to be used for the sentiment analysis task. Another example would be a **spam filtering model** that has been trained on emails of one user (the source distribution) and is applied to a new user who receives significantly different emails (the target distribution). This process of applying the model to a different target distribution is sometimes also known as **domain adaptation**. <Sup>2</Sup>\n",
        "\n",
        "---------\n",
        "<sup> 2. Some people distinguish between **transfer learning** and **domain adaptation**, some don't. These are not very precisely defined terms in the literature.</sup> \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JzpsVzu8ovqK"
      },
      "source": [
        "## A. Cross-Country Generalizability of the Model (20 points)\n",
        "\n",
        "Using a model trained on all the data from the United States, estimate the prevalence of Climate Change Denialism disease for the 8 provinces of the **Dominion of Canada** for the years 2011 to 2014. You may have to modify and retrain your model according to the data and features available to you for Canada. \n",
        "\n",
        "The dataset (i.e. features) for Canada is available as `ca_test_x.csv`. You will submit your final predictions as `ca_predictions.csv` the template for which is provided to you in the handout. As you will notice, the features for Canada are a subset of the features for the USA, therefore, you'll have to train your US based model accordingly.\n",
        "\n",
        "As a submission for this part, you will fill the `ca_predictions.csv` file and submit that along with this Notebook to NYU Classes. You will also submit `ca_predictions.csv` file to Kaggle (see Part B)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJ6leqzmEDIg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "07a38212-9c39-4250-eddd-7ed6c94305c3"
      },
      "source": [
        "ca_test = pd.read_csv(\"/content/drive/My Drive/Data_Science/Assignment/hw9_handout/ca_test_x.csv\")\n",
        "X_train = us_train[list(ca_test.columns)]\n",
        "X_train.drop(['Id', 'states', 'year'], axis=1, inplace=True)\n",
        "y_train=us_train['outcome']\n",
        "X_test=ca_test.drop(['Id', 'states', 'year'], axis=1)\n",
        "\n",
        "X_train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            B          F          H          I          K          L  \\\n",
              "50  55.929102  29.419012  66.509808  72.384352  34.337305  73.123699   \n",
              "51  50.967649  20.082439  47.010948   0.000000  33.217610  70.386448   \n",
              "52  51.193170  22.372542  47.545164  42.160710  33.590842  72.341628   \n",
              "53  58.184308  19.730116  68.379561  69.590570  34.523920  74.687843   \n",
              "54  44.202032  18.320822  33.121350  23.620157  22.953742  61.001589   \n",
              "\n",
              "            M          O          T          W          X         Y  \\\n",
              "50  42.101993  53.302688  31.846101  31.054514  43.672310   0.00000   \n",
              "51  38.274539  41.745910  27.171444  28.687129   0.000000   0.00000   \n",
              "52  39.850550  45.755405  28.047943  27.155292  34.836872   0.00000   \n",
              "53  37.373962  48.113931  33.891264  30.358224  50.488220   0.00000   \n",
              "54  33.546508  33.491069  22.642870  20.192397  30.040491  80.15661   \n",
              "\n",
              "           AA         AC  \n",
              "50  47.718480  60.503087  \n",
              "51  37.736553  58.714818  \n",
              "52  38.223477  52.455878  \n",
              "53  45.040402  68.848340  \n",
              "54  31.650013  42.024312  "
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>B</th>\n",
              "      <th>F</th>\n",
              "      <th>H</th>\n",
              "      <th>I</th>\n",
              "      <th>K</th>\n",
              "      <th>L</th>\n",
              "      <th>M</th>\n",
              "      <th>O</th>\n",
              "      <th>T</th>\n",
              "      <th>W</th>\n",
              "      <th>X</th>\n",
              "      <th>Y</th>\n",
              "      <th>AA</th>\n",
              "      <th>AC</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>50</th>\n",
              "      <td>55.929102</td>\n",
              "      <td>29.419012</td>\n",
              "      <td>66.509808</td>\n",
              "      <td>72.384352</td>\n",
              "      <td>34.337305</td>\n",
              "      <td>73.123699</td>\n",
              "      <td>42.101993</td>\n",
              "      <td>53.302688</td>\n",
              "      <td>31.846101</td>\n",
              "      <td>31.054514</td>\n",
              "      <td>43.672310</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>47.718480</td>\n",
              "      <td>60.503087</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51</th>\n",
              "      <td>50.967649</td>\n",
              "      <td>20.082439</td>\n",
              "      <td>47.010948</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>33.217610</td>\n",
              "      <td>70.386448</td>\n",
              "      <td>38.274539</td>\n",
              "      <td>41.745910</td>\n",
              "      <td>27.171444</td>\n",
              "      <td>28.687129</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>37.736553</td>\n",
              "      <td>58.714818</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52</th>\n",
              "      <td>51.193170</td>\n",
              "      <td>22.372542</td>\n",
              "      <td>47.545164</td>\n",
              "      <td>42.160710</td>\n",
              "      <td>33.590842</td>\n",
              "      <td>72.341628</td>\n",
              "      <td>39.850550</td>\n",
              "      <td>45.755405</td>\n",
              "      <td>28.047943</td>\n",
              "      <td>27.155292</td>\n",
              "      <td>34.836872</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>38.223477</td>\n",
              "      <td>52.455878</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53</th>\n",
              "      <td>58.184308</td>\n",
              "      <td>19.730116</td>\n",
              "      <td>68.379561</td>\n",
              "      <td>69.590570</td>\n",
              "      <td>34.523920</td>\n",
              "      <td>74.687843</td>\n",
              "      <td>37.373962</td>\n",
              "      <td>48.113931</td>\n",
              "      <td>33.891264</td>\n",
              "      <td>30.358224</td>\n",
              "      <td>50.488220</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>45.040402</td>\n",
              "      <td>68.848340</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54</th>\n",
              "      <td>44.202032</td>\n",
              "      <td>18.320822</td>\n",
              "      <td>33.121350</td>\n",
              "      <td>23.620157</td>\n",
              "      <td>22.953742</td>\n",
              "      <td>61.001589</td>\n",
              "      <td>33.546508</td>\n",
              "      <td>33.491069</td>\n",
              "      <td>22.642870</td>\n",
              "      <td>20.192397</td>\n",
              "      <td>30.040491</td>\n",
              "      <td>80.15661</td>\n",
              "      <td>31.650013</td>\n",
              "      <td>42.024312</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 202
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "zPM4ifYdPRjF",
        "outputId": "91b5e338-66e1-4608-f5d6-35994165d378"
      },
      "source": [
        "X_test.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      B      F     H     I     K     L     M     O      T     W      X    Y  \\\n",
              "0  43.0  100.0  44.0  68.0  58.0  44.0  26.0  49.0   47.0  42.0   34.0  0.0   \n",
              "1  48.0   65.0  36.0  64.0  45.0  44.0  33.0  43.0   40.0  40.0   34.0  0.0   \n",
              "2  61.0   55.0  47.0  57.0  62.0  48.0  27.0  60.0   63.0  54.0   39.0  0.0   \n",
              "3  53.0   41.0  56.0   0.0  51.0  41.0  22.0  43.0   62.0  47.0    0.0  0.0   \n",
              "4  77.0   88.0  87.0   0.0  60.0  69.0  28.0  85.0  100.0  52.0  100.0  0.0   \n",
              "\n",
              "     AA     AC  \n",
              "0  84.0   66.0  \n",
              "1  75.0   65.0  \n",
              "2  89.0  100.0  \n",
              "3   0.0    0.0  \n",
              "4  83.0   88.0  "
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>B</th>\n",
              "      <th>F</th>\n",
              "      <th>H</th>\n",
              "      <th>I</th>\n",
              "      <th>K</th>\n",
              "      <th>L</th>\n",
              "      <th>M</th>\n",
              "      <th>O</th>\n",
              "      <th>T</th>\n",
              "      <th>W</th>\n",
              "      <th>X</th>\n",
              "      <th>Y</th>\n",
              "      <th>AA</th>\n",
              "      <th>AC</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>43.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>44.0</td>\n",
              "      <td>68.0</td>\n",
              "      <td>58.0</td>\n",
              "      <td>44.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>49.0</td>\n",
              "      <td>47.0</td>\n",
              "      <td>42.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>84.0</td>\n",
              "      <td>66.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>48.0</td>\n",
              "      <td>65.0</td>\n",
              "      <td>36.0</td>\n",
              "      <td>64.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>44.0</td>\n",
              "      <td>33.0</td>\n",
              "      <td>43.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>75.0</td>\n",
              "      <td>65.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>61.0</td>\n",
              "      <td>55.0</td>\n",
              "      <td>47.0</td>\n",
              "      <td>57.0</td>\n",
              "      <td>62.0</td>\n",
              "      <td>48.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>60.0</td>\n",
              "      <td>63.0</td>\n",
              "      <td>54.0</td>\n",
              "      <td>39.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>89.0</td>\n",
              "      <td>100.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>53.0</td>\n",
              "      <td>41.0</td>\n",
              "      <td>56.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>51.0</td>\n",
              "      <td>41.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>43.0</td>\n",
              "      <td>62.0</td>\n",
              "      <td>47.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>77.0</td>\n",
              "      <td>88.0</td>\n",
              "      <td>87.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>60.0</td>\n",
              "      <td>69.0</td>\n",
              "      <td>28.0</td>\n",
              "      <td>85.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>52.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>83.0</td>\n",
              "      <td>88.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tTXYIVJDOxye"
      },
      "source": [
        "scaler = MinMaxScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test=scaler.fit_transform(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nJSfDHeNPZZH",
        "outputId": "3c3bf565-8387-4ad3-ee8a-f66969c615db"
      },
      "source": [
        "# Defining a range of alpha values for Lasso\n",
        "alphas = np.linspace(0.001,1,100)\n",
        "\n",
        "# Initializing the instance of Ridge\n",
        "lasso = Lasso()\n",
        "\n",
        "# Setting parameter grid for grid search\n",
        "param_grid = {'alpha': alphas}\n",
        "\n",
        "# defining grid search with 5-fold cross validation\n",
        "grid_search = GridSearchCV(lasso, param_grid, scoring='r2', cv = 5)\n",
        "\n",
        "# fitting the train\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Printing the best set of parameters\n",
        "print('Best parameters{}'.format(grid_search.best_params_))\n",
        "\n",
        "# Printing the best score (here score is R squared score)\n",
        "print('Best score {}'.format(grid_search.best_score_))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best parameters{'alpha': 0.011090909090909092}\n",
            "Best score 0.606597208582\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gv1rA5a6Pi0q",
        "outputId": "53e7b430-6b40-4eb8-a664-4e06e5ffde64"
      },
      "source": [
        "linear_lasso_optimal = Lasso(alpha=grid_search.best_params_['alpha'])\n",
        "linear_lasso_optimal.fit(X_train, y_train)\n",
        "\n",
        "def evaluate(X,Y, model, is_test=False):\n",
        "        print (\"Train mean_absolute_error (MSE)\", \n",
        "               mean_absolute_error(Y, model.predict(X)))\n",
        "        print (\"Train R-squared Score (R2)\", \n",
        "               r2_score(Y, model.predict(X)))\n",
        "\n",
        "evaluate(X_train, y_train, linear_lasso_optimal)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('Train mean_absolute_error (MSE)', 0.6743379292806603)\n",
            "('Train R-squared Score (R2)', 0.723125854610794)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lu1OfKAQPvju",
        "outputId": "510c102d-d784-4bf4-eebd-92a82ce0236b"
      },
      "source": [
        "linear_lasso_optimal.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 9.20401375,  8.7232817 ,  8.87039069,  8.36063583,  9.56016717,\n",
              "        9.70366808,  9.0060616 ,  8.51884175,  9.19389384,  8.51306987,\n",
              "        9.34342235,  8.34448389,  8.28236009,  9.99124087,  8.78094252,\n",
              "       11.5449953 ,  8.85742643,  8.28403566,  8.19992046,  8.82215489,\n",
              "        6.97105318,  9.7967199 ,  9.23615441, 10.57746835,  8.94988777,\n",
              "        8.5851952 ,  9.09239234,  8.75214354,  8.42976749,  9.57482778,\n",
              "        9.42038555,  9.94193502])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 206
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zQ9RQl7DUG4x"
      },
      "source": [
        "#This is the best model and is my final submission of kaggle\n",
        "ca_predictions=pd.DataFrame()\n",
        "ca_predictions['Id']=ca_test['Id']\n",
        "ca_predictions['Predicted'] = pd.DataFrame(linear_lasso_optimal.predict(X_test))\n",
        "output_dir = '/content/drive/My Drive/Data_Science/Assignment/'\n",
        "ca_predictions=ca_predictions.to_csv(output_dir+'ca_predictions.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7V8j7kI_WHPB",
        "outputId": "ed7dad34-153a-44ec-cc18-4b04fa61835e"
      },
      "source": [
        "\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "\n",
        "k_range = list(range(1,31))\n",
        "weight_options = [\"uniform\", \"distance\"]\n",
        "\n",
        "param_grid = dict(n_neighbors = k_range, weights = weight_options)\n",
        "#print (param_grid)\n",
        "knn = KNeighborsRegressor()\n",
        "\n",
        "grid = GridSearchCV(knn, param_grid, cv = 10)\n",
        "grid.fit(X_train,y_train)\n",
        "\n",
        "\n",
        "print (grid.best_score_)\n",
        "print (grid.best_params_)\n",
        "print (grid.best_estimator_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7369353759355491\n",
            "{'n_neighbors': 4, 'weights': 'distance'}\n",
            "KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
            "          metric_params=None, n_jobs=None, n_neighbors=4, p=2,\n",
            "          weights='distance')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tfMlCBWEYamL",
        "outputId": "60fb7430-e0f0-4eab-862f-00e0550ad916"
      },
      "source": [
        "best_params = grid.best_params_\n",
        "knn = KNeighborsRegressor(n_neighbors=best_params['n_neighbors'], weights=best_params['weights'])\n",
        "knn.fit(X_train,y_train)\n",
        "predicted_value = knn.predict(X_test)\n",
        "predicted_value"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([10.15379827,  9.62778276,  9.60343147,  8.36378979,  9.04735846,\n",
              "       10.39983411, 10.31420389,  8.11059539, 10.15664619,  8.99621168,\n",
              "       10.33099189,  7.90901447,  7.77447097, 11.60392384,  9.9984013 ,\n",
              "        8.28919905,  9.5208534 ,  8.98302055,  8.52327939,  7.92677283,\n",
              "        9.76551628,  9.6502414 ,  9.69170643,  7.90616127, 10.12873253,\n",
              "        9.37114469,  9.53523568,  9.16254356,  8.21105094, 10.69716281,\n",
              "       10.04922247,  8.2435629 ])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 209
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YLHt0jjJYiCV"
      },
      "source": [
        "ca_predictions=pd.DataFrame()\n",
        "ca_predictions['Id']=ca_test['Id']\n",
        "ca_predictions['Predicted'] = pd.DataFrame(knn.predict(X_test))\n",
        "output_dir = '/content/drive/My Drive/Data_Science/Assignment/'\n",
        "ca_predictions=ca_predictions.to_csv(output_dir+'ca_predictions_knn.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gk6-XiEMFItX"
      },
      "source": [
        "### Rubric\n",
        "\n",
        "- +10 points for logical and reasonable steps to training and testing the models using the techniques taught in the course\n",
        "- +10 points showing code and evaluation of **at least two regression models** at least one of which makes the same predictions as submitted on Kaggle and in the document `ca_predictions.csv`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DhewfxmLpQYj"
      },
      "source": [
        "## B. Kaggle Submission (20 points)\n",
        "\n",
        "You will submit your predictions as `ca_predictions.csv` with the two columns `Id` and `Predicted` to Kaggle [here](https://www.kaggle.com/t/32971211c35047fcbeb5538e48fadd7d). \n",
        "\n",
        "You will be evaluated on the `Mean Absolute Error` scoring metric.\n",
        "\n",
        "There is one benchmark/baseline that we have provided you on Kaggle that you will have to meet/beat to receive all the points.\n",
        "\n",
        "Note that the score you see on Kaggle Leaderboard for your submission is only based on 75% of the dataset (i.e. 24 data points) -- we have hidden 25% of the dataset (8 data points), and your score on those will only be revealed once the competition ends.\n",
        "\n",
        "You have a maximum for 10 submissions per day on Kaggle. Before submitting the notebook, enter your Kaggle username in the **Kaggle Username** section above."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pRVWGA6-EmVg"
      },
      "source": [
        "### Rubric\n",
        "\n",
        "- +20 points for achieving/crossing the baseline provided across both public (15 points) and hidden data points (5 points)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N08hHBwwoHHT"
      },
      "source": [
        "## *Concepts required to complete this task*\n",
        "\n",
        "*   Basics of Machine Learning\n",
        "*   Basics of Regression\n",
        "*   Feature Engineering\n",
        "*   Concept of Transfer Learning"
      ]
    }
  ]
}